"""Phase 1 Implementer agent skeleton.

Converts the approved design into an execution plan the Tester can validate
against. The implementation intentionally writes deterministic markdown so
phase demos remain reproducible.
"""

from __future__ import annotations

import datetime
import sys
from pathlib import Path
from typing import Mapping, Sequence

if __package__ is None or __package__ == "":
    sys.path.append(str(Path(__file__).resolve().parents[1]))

from audit import log_handoff

PROJECT_ROOT = Path(__file__).resolve().parents[1]
DOCS_DIR = PROJECT_ROOT / "docs"
IMPLEMENTATION_PLAN_PATH = DOCS_DIR / "IMPLEMENTATION_PLAN.md"


def _as_list(values: Sequence[object] | object | None) -> list[str]:
    if values is None:
        return []
    if isinstance(values, (str, bytes)):
        return [str(values)]
    return [str(item) for item in values]


class Implementer:
    """Produce an execution plan and checklist for the scenario."""

    def __init__(self, phase: str = "1") -> None:
        self.phase = phase

    def create_execution_plan(
        self,
        scenario: Mapping[str, object],
        *,
        design_path: Path | None = None,
        output_path: Path | None = None,
    ) -> Path:
        """Write an implementation checklist for downstream testing."""
        DOCS_DIR.mkdir(parents=True, exist_ok=True)
        target = output_path or IMPLEMENTATION_PLAN_PATH

        title = str(scenario.get("title") or "Phase Deliverable")
        focus_areas = _as_list(scenario.get("focus_areas"))
        acceptance = _as_list(scenario.get("acceptance_criteria"))

        tasks = [
            "Extend audit logger utilities with concern mirroring helpers.",
            "Persist concern snapshots into Markdown for human review.",
            "Instrument interaction stub with additional lifecycle commands.",
            "Integrate QA policy enforcement to block promotion on open concerns.",
        ]
        focus_section = "\n".join(f"- {item}" for item in focus_areas) or "- Align focus areas with design output."
        acceptance_section = "\n".join(f"- {item}" for item in acceptance) or "- Acceptance criteria to be detailed with Tester."
        task_section = "\n".join(f"- [ ] {task}" for task in tasks)

        timestamp = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%SZ")
        if design_path:
            try:
                design_display = design_path.relative_to(PROJECT_ROOT)
            except ValueError:
                design_display = design_path
            design_reference = f"Design reference: `{design_display}`."
        else:
            design_reference = "Design reference: pending."

        content = "\n".join(
            [
                f"# Implementation Plan â€” {title}",
                "",
                "## Alignment",
                focus_section,
                "",
                "## Task Checklist",
                task_section,
                "",
                "## Acceptance Alignment",
                acceptance_section,
                "",
                "## Dependencies",
                "- Designer spec approval (Phase 1).",
                "- Updated audit utilities for concern lifecycle.",
                "- Tester-provided fixtures reflecting QA policy thresholds.",
                "",
                "## Notes",
                design_reference,
                "",
                f"_Auto-generated by Implementer.create_execution_plan at {timestamp}._",
            ]
        )

        target.write_text(content + "\n", encoding="utf-8")

        log_handoff(
            phase=self.phase,
            from_agent="implementer",
            to_agent="tester",
            summary=f"Drafted execution plan for '{title}'.",
            artifacts=[str(target.relative_to(PROJECT_ROOT))],
            concerns=[],
            metadata={"scenario_title": title, "timestamp": timestamp},
        )

        return target
