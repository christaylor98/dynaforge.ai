"""Phase 1 Tester agent skeleton.

Produces deterministic test assets for the active scenario so the human reviewer
has a clear QA plan before approving promotion.
"""

from __future__ import annotations

import datetime
import sys
from pathlib import Path
from typing import Mapping

if __package__ is None or __package__ == "":
    sys.path.append(str(Path(__file__).resolve().parents[1]))

from audit import log_handoff

PROJECT_ROOT = Path(__file__).resolve().parents[1]
TESTS_DIR = PROJECT_ROOT / "tests"
TEST_PLAN_PATH = TESTS_DIR / "TEST_PLAN.md"
TEST_RESULTS_PATH = TESTS_DIR / "TEST_RESULTS.md"


class Tester:
    """Generate QA collateral for the Phase 1 scenario."""

    def __init__(self, phase: str = "1") -> None:
        self.phase = phase

    def prepare_phase_test_assets(
        self,
        scenario: Mapping[str, object],
        *,
        plan_path: Path | None = None,
        results_path: Path | None = None,
    ) -> tuple[Path, Path]:
        """Create a refreshed test plan and placeholder results summary."""
        TESTS_DIR.mkdir(parents=True, exist_ok=True)
        plan_target = plan_path or TEST_PLAN_PATH
        results_target = results_path or TEST_RESULTS_PATH

        title = str(scenario.get("title") or "Phase Deliverable")
        objective = str(scenario.get("objective") or "Quality objective pending.")

        timestamp = datetime.datetime.utcnow().strftime("%Y-%m-%d %H:%M:%SZ")

        plan_content = "\n".join(
            [
                "# Test Plan — Phase 1",
                "",
                f"## Scenario — {title}",
                objective,
                "",
                "## Objectives",
                "- Validate concern logging mirrors into Markdown summaries.",
                "- Exercise interaction stub lifecycle commands for deterministic responses.",
                "- Confirm QA policy enforcement blocks promotions on open concerns.",
                "",
                "## Test Strategy",
                "- Unit tests for concern synchronization utilities.",
                "- Integration walk-through via `make phase1-demo` (orchestrator run).",
                "- Manual verification of pause/resume and approval gating paths.",
                "",
                "## Environments",
                "- Local developer workstation (Python 3.11+).",
                "- Continuous integration pipeline (TBD) with audit artifact capture.",
                "",
                "## Entry Criteria",
                "- Phase 1 design and implementation plans approved by human reviewer.",
                "- Concern lifecycle helpers available in the codebase.",
                "- Interaction stub expanded with lifecycle commands.",
                "",
                "## Exit Criteria",
                "- All critical tests passing with evidence stored under `artifacts/phase1/`.",
                "- No unresolved high/critical concerns in `audit/concerns.jsonl`.",
                "- Approval marker recorded in documentation.",
                "",
                "## Test Cases (Draft)",
                "| ID | Description | Type | Expected Evidence |",
                "| -- | ----------- | ---- | ----------------- |",
                "| TC-101 | Sync open concerns to Markdown and verify table contents | Functional | `tests/test_concern_tools.py` pass + rendered Markdown snippet |",
                "| TC-102 | Issue `/ack` and `/resolve` via stub, confirm audit log entries | Integration | `artifacts/phase1/demo/commands.jsonl` capture |",
                "| TC-103 | Introduce failing QA results to trigger policy block and concern | Negative | `tests/test_policy_parser.py` extension + concern record |",
                "",
                f"_Auto-generated by Tester.prepare_phase_test_assets at {timestamp}._",
            ]
        )
        plan_target.write_text(plan_content + "\n", encoding="utf-8")

        results_content = "\n".join(
            [
                "# Test Results — Phase 1",
                "",
                "## Summary",
                "Phase 1 demo not yet executed; results will be populated after orchestration run.",
                "",
                "## Pending Actions",
                "- Execute new unit tests for concern synchronization.",
                "- Capture interaction stub command transcripts.",
                "- Record QA policy enforcement outcomes.",
                "",
                f"_Auto-generated placeholder at {timestamp}._",
            ]
        )
        results_target.write_text(results_content + "\n", encoding="utf-8")

        log_handoff(
            phase=self.phase,
            from_agent="tester",
            to_agent="human_review",
            summary=f"Prepared Phase 1 QA plan for '{title}'.",
            artifacts=[
                str(plan_target.relative_to(PROJECT_ROOT)),
                str(results_target.relative_to(PROJECT_ROOT)),
            ],
            concerns=[],
            metadata={"scenario_title": title, "timestamp": timestamp},
        )

        return plan_target, results_target
