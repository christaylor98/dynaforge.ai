"""Subsystem synthesis for Codexa discovery runs.

This module consumes the semantic manifest generated by the summariser
and produces a higher-level subsystem/architecture description.  The
current implementation focuses on providing a clear integration point
for adaptive AI reasoning â€“ the heuristics included here are intentionally
lightweight so they can be replaced by model-powered synthesis without
touching the surrounding pipeline.
"""

from __future__ import annotations

from dataclasses import dataclass, field
import json
from pathlib import Path
from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence

from .prompts import PromptRegistry, render_prompt


DEFAULT_SEMANTIC_MANIFEST = Path(".codexa/discovery/manifest_semantic.json")
DEFAULT_SYSTEM_MANIFEST = Path(".codexa/discovery/manifest_system.json")


@dataclass
class ModuleSummary:
    """Normalised view of a semantic manifest entry."""

    file: str
    summary: str
    responsibilities: Sequence[str] = field(default_factory=tuple)
    dependencies: Sequence[str] = field(default_factory=tuple)
    confidence: float = 0.0

    @property
    def domain_hint(self) -> str:
        """Return the top-level directory (used for initial clustering)."""

        return self.file.split("/", 1)[0] if "/" in self.file else "root"

    @classmethod
    def from_payload(cls, payload: Mapping[str, Any]) -> "ModuleSummary":
        return cls(
            file=str(payload.get("file") or ""),
            summary=str(payload.get("summary") or ""),
            responsibilities=tuple(payload.get("responsibilities") or ()),
            dependencies=tuple(payload.get("dependencies") or ()),
            confidence=float(payload.get("confidence") or 0.0),
        )


@dataclass
class SubsystemCandidate:
    """Grouped module collection awaiting AI enrichment."""

    name: str
    modules: List[ModuleSummary]

    def to_prompt_block(self) -> str:
        lines = [f"Subsystem: {self.name}"]
        for module in self.modules:
            lines.append(f"- {module.file}: {module.summary}")
        return "\n".join(lines)


def _load_json(path: Path) -> List[Mapping[str, Any]]:
    if not path.exists():
        return []
    try:
        payload = json.loads(path.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        return []
    if isinstance(payload, list):
        return payload
    return []


def _ensure_directory(path: Path) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)


class SubsystemSynthesizer:
    """Aggregate module summaries into subsystem descriptions."""

    def __init__(
        self,
        semantic_manifest: Path = DEFAULT_SEMANTIC_MANIFEST,
        system_manifest: Path = DEFAULT_SYSTEM_MANIFEST,
        *,
        prompt_registry: Optional[PromptRegistry] = None,
        prompt_profile: str = "default",
        model_invokers: Optional[Mapping[str, Any]] = None,
        focus_text: str = "",
    ) -> None:
        self.semantic_manifest = semantic_manifest
        self.system_manifest = system_manifest
        self.prompt_registry = prompt_registry or PromptRegistry.load()
        self.prompt_profile = prompt_profile
        self.model_invokers = dict(model_invokers or {})
        self.focus_text = focus_text

    def load_modules(self) -> List[ModuleSummary]:
        entries = _load_json(self.semantic_manifest)
        modules = [ModuleSummary.from_payload(entry) for entry in entries if entry]
        return [module for module in modules if module.file]

    def cluster_modules(self, modules: Iterable[ModuleSummary]) -> List[SubsystemCandidate]:
        buckets: Dict[str, List[ModuleSummary]] = {}
        for module in modules:
            buckets.setdefault(module.domain_hint, []).append(module)

        candidates = []
        for name, items in sorted(buckets.items()):
            if not items:
                continue
            candidates.append(SubsystemCandidate(name=name, modules=sorted(items, key=lambda m: m.file)))
        return candidates

    def synthesise(self) -> List[Dict[str, Any]]:
        modules = self.load_modules()
        if not modules:
            return []

        candidates = self.cluster_modules(modules)
        subsystems = [self._describe_candidate(candidate) for candidate in candidates]
        self._write_manifest(subsystems)
        return subsystems

    def _describe_candidate(self, candidate: SubsystemCandidate) -> Dict[str, Any]:
        """Build a subsystem payload.

        The body intentionally uses deterministic heuristics as a fallback.  The
        `call_model` hook can be replaced with a richer AI-powered description
        without changing downstream consumers.
        """

        description = {
            "subsystem": candidate.name,
            "modules": [module.file for module in candidate.modules],
            "purpose": self._heuristic_purpose(candidate),
            "inputs": self._collect_inputs(candidate.modules),
            "outputs": self._collect_outputs(candidate.modules),
            "depends_on": self._collect_dependencies(candidate.modules),
            "interacts_with": [],
            "risks": [],
            "entry_points": self._guess_entrypoints(candidate.modules),
            "confidence": round(self._average_confidence(candidate.modules), 3),
        }

        ai_summary = self._call_model(candidate)
        if ai_summary:
            description.update(ai_summary)

        return description

    @staticmethod
    def _collect_dependencies(modules: Iterable[ModuleSummary]) -> List[str]:
        deps: set[str] = set()
        for module in modules:
            for dep in module.dependencies:
                deps.add(str(dep))
        return sorted(deps)

    @staticmethod
    def _collect_inputs(modules: Iterable[ModuleSummary]) -> List[str]:
        inputs: set[str] = set()
        for module in modules:
            for token in module.summary.split():
                if token.endswith("_input"):
                    inputs.add(token)
        return sorted(inputs)

    @staticmethod
    def _collect_outputs(modules: Iterable[ModuleSummary]) -> List[str]:
        outputs: set[str] = set()
        for module in modules:
            for token in module.summary.split():
                if token.endswith("_output"):
                    outputs.add(token)
        return sorted(outputs)

    @staticmethod
    def _guess_entrypoints(modules: Iterable[ModuleSummary]) -> List[str]:
        entries: list[str] = []
        for module in modules:
            if module.file.endswith(("__main__.py", "main.py")):
                entries.append(module.file)
        return entries

    @staticmethod
    def _average_confidence(modules: Iterable[ModuleSummary]) -> float:
        scores = [module.confidence for module in modules]
        return sum(scores) / max(1, len(scores))

    @staticmethod
    def _heuristic_purpose(candidate: SubsystemCandidate) -> str:
        summary_tokens = []
        for module in candidate.modules:
            summary_tokens.extend(module.summary.split())
        keywords = sorted({token.strip(".,") for token in summary_tokens if len(token) > 4})
        if not keywords:
            return "Subsystem purpose pending AI synthesis."
        sample = ", ".join(keywords[:6])
        return f"Likely concerns: {sample}"

    def _call_model(self, candidate: SubsystemCandidate) -> Dict[str, Any]:
        if not self.model_invokers:
            return {}

        template = self.prompt_registry.get(self.prompt_profile, "architecture")
        focus_block = f"{self.focus_text}\n\n" if self.focus_text else ""
        module_lines = []
        for module in candidate.modules:
            deps = ", ".join(module.dependencies) if module.dependencies else "none"
            module_lines.append(
                f"- {module.file}: {module.summary} (deps: {deps})"
            )
        module_summaries = "\n".join(module_lines)

        prompt = render_prompt(
            template,
            path=candidate.name,
            snippet="",
            focus_block=focus_block,
            module_summaries=module_summaries,
        )

        model_id = "cloud://gpt-advanced"
        invoker = self.model_invokers.get(model_id)
        if invoker is None and self.model_invokers:
            model_id, invoker = next(iter(self.model_invokers.items()))
        if invoker is None:
            return {}

        try:
            raw = invoker(model_id, prompt)
            payload = json.loads(raw)
        except (json.JSONDecodeError, TypeError):
            return {}

        if isinstance(payload, dict):
            return payload
        return {}

    def _write_manifest(self, subsystems: List[Dict[str, Any]]) -> None:
        payload = {"subsystems": subsystems, "generated_at": self._timestamp()}
        _ensure_directory(self.system_manifest)
        self.system_manifest.write_text(
            json.dumps(payload, indent=2, sort_keys=True), encoding="utf-8"
        )

    @staticmethod
    def _timestamp() -> str:
        from datetime import datetime

        return datetime.utcnow().isoformat()


def synthesise_subsystems(
    semantic_manifest: Path | None = None,
    system_manifest: Path | None = None,
    *,
    prompt_registry: Optional[PromptRegistry] = None,
    prompt_profile: str = "default",
    model_invokers: Optional[Mapping[str, Any]] = None,
    focus_text: str = "",
) -> List[Dict[str, Any]]:
    synthesiser = SubsystemSynthesizer(
        semantic_manifest=semantic_manifest or DEFAULT_SEMANTIC_MANIFEST,
        system_manifest=system_manifest or DEFAULT_SYSTEM_MANIFEST,
        prompt_registry=prompt_registry,
        prompt_profile=prompt_profile,
        model_invokers=model_invokers,
        focus_text=focus_text,
    )
    return synthesiser.synthesise()


if __name__ == "__main__":
    synthesise_subsystems()
